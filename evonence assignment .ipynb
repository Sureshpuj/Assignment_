{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f62647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function validate_data(data) that checks if a list of dictionaries \n",
    "# (e.g., [{\"name\": \"Alice\", \"age\": 30}, {\"name\": \"Bob\", \"age\": \"25\"}]) contains \n",
    "# valid integer values for the \"age\" key. Return a list of invalidÂ entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5085787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(data):\n",
    "    invalid_entries = []\n",
    "    \n",
    "    for entry in data:\n",
    "        # Check if 'age' key exists and the value is an integer\n",
    "        if 'age' not in entry or not isinstance(entry['age'], int):\n",
    "            invalid_entries.append(entry)\n",
    "    \n",
    "    return invalid_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7049aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Bob', 'age': '25'}, {'name': 'Charlie'}]\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\"name\": \"Alice\", \"age\": 30},\n",
    "    {\"name\": \"Bob\", \"age\": \"25\"},\n",
    "    {\"name\": \"Charlie\"},\n",
    "    {\"name\": \"David\", \"age\": 40}\n",
    "]\n",
    "\n",
    "print(validate_data(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694543f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'calculate_sum' executed in 0.039543 seconds\n",
      "Sum: 500000500000\n"
     ]
    }
   ],
   "source": [
    "# Create a decorator @log_execution_time that logs the time taken to execute a function.\n",
    "# Use it to log the runtime of a sample function calculate_sum(n) that returns the sum of numbers from 1 to n.\n",
    "import time\n",
    "import functools\n",
    "\n",
    "# Decorator to log execution time\n",
    "def log_execution_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record start time\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()    # Record end time\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Function '{func.__name__}' executed in {execution_time:.6f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Sample function to use the decorator on\n",
    "@log_execution_time\n",
    "def calculate_sum(n):\n",
    "    return sum(range(1, n + 1))\n",
    "\n",
    "# Example usage\n",
    "total = calculate_sum(1000000)\n",
    "print(\"Sum:\", total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26eeded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of income: -0.75\n",
      "Filled missing values with mode: 48000.0\n",
      "\n",
      "Updated DataFrame:\n",
      "      name   income\n",
      "0    Alice  50000.0\n",
      "1      Bob  52000.0\n",
      "2  Charlie  48000.0\n",
      "3    David  48000.0\n",
      "4      Eva  51000.0\n",
      "5    Frank  48000.0\n"
     ]
    }
   ],
   "source": [
    "#  Missing Value Handling\n",
    "# Task: A dataset has missing values in the \"income\" column. Write code to:\n",
    "\n",
    "# 1. Replace missing values with the median if the data is normally distributed.\n",
    "\n",
    "# 2. Replace with the mode if skewed.\n",
    "# Use Pandas and a skewness threshold of 0.5.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'],\n",
    "    'income': [50000, 52000, np.nan, 48000, 51000, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "skewness = df['income'].skew(skipna=True)\n",
    "print(f\"Skewness of income: {skewness:.2f}\")\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "if abs(skewness) <= threshold:\n",
    "    median_value = df['income'].median()\n",
    "    df['income'].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled missing values with median: {median_value}\")\n",
    "else:\n",
    "    mode_value = df['income'].mode()[0]\n",
    "    df['income'].fillna(mode_value, inplace=True)\n",
    "    print(f\"Filled missing values with mode: {mode_value}\")\n",
    "\n",
    "# Final output\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676a3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               text                     cleaned_tokens\n",
      "0                      Hello World!                     [hello, world]\n",
      "1  Pandas is GREAT @ data-cleaning.  [pandas, is, great, datacleaning]\n",
      "2           Python > Java? Maybe...              [python, java, maybe]\n",
      "3        E-mail me at: abc@xyz.com!         [email, me, at, abcxyzcom]\n"
     ]
    }
   ],
   "source": [
    " # Text Pre-processing\n",
    "# Task: Clean a text column in a DataFrame by:\n",
    "\n",
    "# 1. Converting to lowercase.\n",
    "\n",
    "# 2. Removing special characters (e.g., !, @).\n",
    "\n",
    "# 3. Tokenizing the text.\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'text': [\n",
    "        \"Hello World!\",\n",
    "        \"Pandas is GREAT @ data-cleaning.\",\n",
    "        \"Python > Java? Maybe...\",\n",
    "        \"E-mail me at: abc@xyz.com!\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['cleaned_text'] = df['text'].str.lower()\n",
    "                                                                                              \n",
    "df['cleaned_text'] = df['cleaned_text'].str.replace('[^a-z0-9 ]', '', regex=True)\n",
    "\n",
    "df['cleaned_tokens'] = df['cleaned_text'].str.split()\n",
    "\n",
    "print(df[['text', 'cleaned_tokens']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee66d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "Best CV Accuracy: 0.9428571428571428\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "# Task: Use GridSearchCV to find the best max_depth (values: [3, 5, 7]) \n",
    "# n_estimators (values: [50, 100]) for a Random Forest classifier.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load sample dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# 2. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Define the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 4. Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "# 5. Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# 6. Fit on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 7. Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# 8. Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70431661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Evaluation Metric\n",
    "# Task: Implement a custom metric weighted_accuracy where class 0 has a weight of 1 and class 1 has a weight of 2.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Custom weighted accuracy function\n",
    "def weighted_accuracy(y_true, y_pred):\n",
    "    weights = {0: 1, 1: 2}  # Define class weights\n",
    "    correct = 0\n",
    "    total_weight = 0\n",
    "\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        weight = weights.get(yt, 1)  # Default weight = 1 for any other class\n",
    "        if yt == yp:\n",
    "            correct += weight\n",
    "        total_weight += weight\n",
    "\n",
    "    return correct / total_weight if total_weight != 0 else 0\n",
    "\n",
    "# Create a scorer object for use in GridSearchCV or model evaluation\n",
    "weighted_accuracy_scorer = make_scorer(weighted_accuracy, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48211b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea36a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e4b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
